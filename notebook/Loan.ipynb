{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction: Logistic Regression and Decision Tree Classifiers\n",
    "\n",
    "This notebook demonstrates how to preprocess a loan dataset, build machine learning models (Logistic Regression and Decision Tree) for loan approval prediction, evaluate their performance, and save the trained models for deployment.\n",
    "\n",
    "## Importing Libraries and Packages\n",
    "\n",
    "We import the necessary libraries required for data manipulation, preprocessing, model training, evaluation, and saving models. Below is a brief explanation of each library:\n",
    "\n",
    "1. pandas: For loading, exploring, and manipulating the dataset.\n",
    "2. sklearn.model_selection.train_test_split: Splits the dataset into training and testing sets for model evaluation.\n",
    "3. sklearn.preprocessing.LabelEncoder: Encodes categorical variables into numeric format.\n",
    "4. sklearn.impute.SimpleImputer: Handles missing data by replacing or removing null values.\n",
    "5. sklearn.preprocessing.StandardScaler: Scales numerical features for improved model performance.\n",
    "6. sklearn.linear_model.LogisticRegression: Builds a logistic regression model for binary classification.\n",
    "7. sklearn.tree.DecisionTreeClassifier: Builds a decision tree classifier for predictions.\n",
    "8. sklearn.metrics.accuracy_score: Evaluates model accuracy.\n",
    "9. pickle: Saves and loads trained models for deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing Necessary Libraries\n",
    "\n",
    "import pandas as pd \n",
    "# For data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split  \n",
    "# For splitting data into train and test sets\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  \n",
    "# For encoding categorical variables and scaling features\n",
    "from sklearn.impute import SimpleImputer  \n",
    "# For handling missing values\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "# Logistic Regression model\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "# Decision Tree model\n",
    "from sklearn.metrics import accuracy_score  \n",
    "# For evaluating the models\n",
    "import pickle  \n",
    "# For saving and loading the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 : LOAD AND EXPLORE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married  Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No         0.0      Graduate            No   \n",
      "1  LP001003   Male     Yes         1.0      Graduate            No   \n",
      "2  LP001005   Male     Yes         0.0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes         0.0  Not Graduate            No   \n",
      "4  LP001008   Male      No         0.0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n",
      "Y    411\n",
      "N    187\n",
      "Name: Loan_Status, dtype: int64\n",
      "Loan_ID               0\n",
      "Gender                0\n",
      "Married               0\n",
      "Dependents           12\n",
      "Education             0\n",
      "Self_Employed         0\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           21\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       49\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "loan_data = pd.read_csv(r'C:\\Users\\naray\\Downloads\\LoanApprovalPrediction.csv')\n",
    "\n",
    "# Display the first few rows to inspect the structure of the dataset\n",
    "print(loan_data.head())\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(loan_data['Loan_Status'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(loan_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Handling Missing values\n",
    "\n",
    "Why Handle Missing Values?\n",
    "\n",
    "Missing values can lead to inaccurate predictions, biases, and errors in machine learning models. Many algorithms cannot process incomplete data, and ignoring this step may result in poor performance.\n",
    "\n",
    "Why Did We Remove Instead of Filling Missing Values?\n",
    "\n",
    "In this dataset, missing values were present in critical columns such as LoanAmount, Loan_Amount_Term, Credit_History, etc., which are key predictors of loan approval.\n",
    "\n",
    "Removing Missing Values: Ensures the data used for training is clean and reliable. Since these columns are crucial, imputing them might introduce noise or incorrect information. For example:\n",
    "Filling Credit_History with an average or mode could distort its influence on loan decisions.\n",
    "Loan amount is highly variable, making it unsuitable for mean or median imputation.\n",
    "\n",
    "Benefit: By removing rows with missing values, we maintain the integrity of our dataset, ensuring only complete and valid data is used for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID              0\n",
      "Gender               0\n",
      "Married              0\n",
      "Dependents           0\n",
      "Education            0\n",
      "Self_Employed        0\n",
      "ApplicantIncome      0\n",
      "CoapplicantIncome    0\n",
      "LoanAmount           0\n",
      "Loan_Amount_Term     0\n",
      "Credit_History       0\n",
      "Property_Area        0\n",
      "Loan_Status          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values in critical columns\n",
    "loan_data.dropna(subset=['LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Gender', \n",
    "                         'Married', 'Dependents', 'Self_Employed'], inplace=True)\n",
    "\n",
    "# Verify if missing values are handled\n",
    "print(loan_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encoding Categorical Variables\n",
    "\n",
    "Why Encode Categorical Variables?\n",
    "\n",
    "Machine learning algorithms work with numerical data. Categorical variables like Gender, Married, and Property_Area need to be converted into numerical values for the model to process them.\n",
    "\n",
    "How Encoding Helps:\n",
    "\n",
    "Label Encoding: Converts categories into numeric representations (e.g., Male=0, Female=1), which helps algorithms interpret the data.\n",
    "Ensures that categorical features are integrated into the model, retaining their predictive power.\n",
    "Benefit: Encoding allows us to include categorical variables in our models, ensuring they contribute to the prediction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "loan_data['Gender'] = label_encoder.fit_transform(loan_data['Gender'])\n",
    "loan_data['Married'] = label_encoder.fit_transform(loan_data['Married'])\n",
    "loan_data['Education'] = label_encoder.fit_transform(loan_data['Education'])\n",
    "loan_data['Self_Employed'] = label_encoder.fit_transform(loan_data['Self_Employed'])\n",
    "loan_data['Property_Area'] = label_encoder.fit_transform(loan_data['Property_Area'])\n",
    "loan_data['Loan_Status'] = label_encoder.fit_transform(loan_data['Loan_Status'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Defining Features and Target in Machine Learning\n",
    "In machine learning, defining the features (independent variables) and the target (dependent variable) is an important step for training the model. The features are the input variables that the model uses to make predictions, while the target is the output variable the model tries to predict.\n",
    "\n",
    "Hereâ€™s a breakdown of the process in Python:\n",
    "\n",
    "Defining Features (X) and Target (y)\n",
    "\n",
    "Features (X): These are the independent variables that the model uses to make predictions. In this case, we remove Loan_ID (an identifier) and Loan_Status (the target) from the features, leaving only the relevant data for prediction.\n",
    "\n",
    "Target (y): The dependent variable, which is Loan_Status in this case, represents the output the model needs to predict (loan approval status).\n",
    "\n",
    "Why is this Important?\n",
    "Correctly defining X and y ensures the model has the right input data to learn from and knows which variable to predict, allowing for accurate training and evaluation.\n",
    "\n",
    "Benefits\n",
    "This approach helps streamline the data for model training, focusing on relevant features and correctly identifying the target variable for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 11) (505,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = loan_data.drop(columns=['Loan_ID', 'Loan_Status'])\n",
    "y = loan_data['Loan_Status']\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Splitting Data into Training and Testing Sets\n",
    "Purpose: Splitting the dataset into two sets:\n",
    "\n",
    "Training set (70%): Used to train the model.\n",
    "Testing set (30%): Used to evaluate the modelâ€™s performance on unseen data.\n",
    "\n",
    "Why Split the Data?: This ensures the model is trained on a portion of the data and evaluated on data it hasn't seen before, preventing overfitting and providing a realistic performance estimate.\n",
    "\n",
    "Benefit:\n",
    "\n",
    "Training Set: Used to train the model.\n",
    "Testing Set: Used to evaluate the modelâ€™s accuracy and ensure it generalizes well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 11) (152, 11) (353,) (152,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Feature Scaling\n",
    "Why Scale Features?\n",
    "Different features in the dataset may have varying ranges (e.g., Income could range from 1,000 to 100,000, while LoanAmount could range from 100 to 5,000). This disparity can cause models like Logistic Regression to assign undue importance to larger-scaled features.\n",
    "\n",
    "StandardScaler: Scales features to have a mean of 0 and a standard deviation of 1, making all features comparable.\n",
    "\n",
    "Benefit:\n",
    "\n",
    "Improves model convergence during training.\n",
    "Ensures algorithms that are sensitive to feature magnitudes (e.g., Logistic Regression) perform optimally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Why Logistic Regression and Decision Tree?\n",
    "\n",
    "Logistic Regression: A baseline algorithm for binary classification tasks, known for its simplicity and interpretability.\n",
    "Decision Tree: A more flexible algorithm that can model complex decision boundaries and handle categorical and numerical data.\n",
    "Benefit: Using two models allows us to compare their performance and select the one that works best for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Purpose:\n",
    "\n",
    "* Train Logistic Regression model: The LogisticRegression class from sklearn.linear_model is used to create a logistic regression model. The model is trained using the training data (X_train_scaled and y_train).\n",
    "* Evaluate Model: After training the model, predictions are made using the test set (X_test_scaled), and the accuracy of these predictions is calculated by comparing them to the actual outcomes (y_test). This accuracy gives a measure of how well the model performs.\n",
    "\n",
    "Why Logistic Regression?:\n",
    "* Binary Classification: Logistic Regression is particularly well-suited for binary classification tasks, where the goal is to classify data into two categories (in this case, whether a loan is approved or denied).\n",
    "* Simplicity and Interpretability: Logistic Regression is a simple and interpretable algorithm. It outputs probabilities, which can be helpful for understanding the likelihood of loan approval and making informed decisions.\n",
    "* Effectiveness with Linearly Separable Data: While it may not be the best model for highly complex or non-linear data, Logistic Regression works well when the decision boundary between classes is approximately linear. In financial applications, such as loan approval, the relationship between features and the target is often linear or can be approximated by linear boundaries.\n",
    "\n",
    "Why Use the max_iter=500 Parameter?\n",
    "The max_iter parameter controls the number of iterations for the optimization algorithm. Setting it to 500 ensures that the algorithm has enough iterations to converge and find the optimal parameters. This is useful for avoiding issues where the algorithm may not converge (especially when the data is more complex).\n",
    "\n",
    "Model Evaluation:\n",
    "\n",
    "* Accuracy Score: The accuracy_score function from sklearn.metrics is used to calculate the percentage of correct predictions made by the model. It compares the predicted loan approval status (y_pred_log_reg) against the actual values (y_test) and outputs a percentage of accurate predictions.\n",
    "* Result: The result gives an idea of how well the Logistic Regression model performs in predicting loan approval.\n",
    "\n",
    "In Summary:\n",
    "Logistic Regression is a simple, interpretable model ideal for binary classification tasks like loan approval prediction.\n",
    "The model's performance is evaluated based on accuracy, which provides a straightforward measure of how well the model is performing on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 84.87%\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "Purpose:\n",
    "* Train Decision Tree model: The DecisionTreeClassifier from sklearn.tree is used to train a Decision Tree model. The model is fit using the training data (X_train and y_train), learning patterns from the features to predict the target variable (loan approval status).\n",
    "* Evaluate Model: After training, predictions are made on the test data (X_test), and the accuracy of the model is assessed by comparing the predicted loan approvals (y_pred_tree) with the actual outcomes (y_test).\n",
    "\n",
    "Why Decision Tree?:\n",
    "* Interpretability: One of the main advantages of Decision Trees is that they are highly interpretable. The decision-making process is transparent and easy to understand. This is particularly useful in finance, where stakeholders need to understand why a decision was made (e.g., why a loan was approved or denied).\n",
    "* Non-linear Relationships: Unlike linear models like Logistic Regression, Decision Trees can handle non-linear relationships between features and the target variable. For example, certain interactions between income, credit score, and loan amount might be better captured with a tree structure rather than a simple linear model.\n",
    "* Feature Importance: Decision Trees can also help identify the most important features for prediction. By examining the structure of the tree, we can see which features (e.g., credit score, income) had the most significant impact on loan approval decisions.\n",
    "* Versatility: Decision Trees can handle both numerical and categorical data without the need for extensive preprocessing like scaling or encoding (though they still benefit from it). This makes them versatile for different types of datasets.\n",
    "\n",
    "Model Evaluation:\n",
    "* Accuracy Score: As with Logistic Regression, we use accuracy_score to measure how well the Decision Tree model performs. The accuracy score compares the predicted results (y_pred_tree) with the actual values (y_test), providing a percentage of correct predictions.\n",
    "* Result: The accuracy score gives an indication of how well the Decision Tree generalizes to unseen data. A high accuracy score would suggest that the model is performing well, while a lower score might indicate that the model is overfitting or underfitting the data.\n",
    "\n",
    "In Summary:\n",
    "* Decision Trees are a powerful, interpretable model for both linear and non-linear relationships. They excel in handling complex decision-making scenarios like loan approval prediction, where factors may interact in non-linear ways.\n",
    "* The model's performance is evaluated based on accuracy, providing insight into how well the model predicts loan approval or denial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 73.68%\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Accuracy: {tree_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models\n",
    "Why Use Accuracy?\n",
    "Accuracy is a basic metric that tells us the percentage of correct predictions. While other metrics like precision and recall are also important, accuracy gives an overall sense of how well the model is performing.\n",
    "\n",
    "Benefit: Evaluation ensures the chosen model meets the desired performance level before deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of Saving Models and Scaler\n",
    "\n",
    "Saving the Scaler:\n",
    "\n",
    "What: The scaler.pkl file stores the StandardScaler object.\n",
    "Why: It ensures that the same scaling transformation is applied to new input data during prediction, maintaining consistency in the model's behavior when processing new data.\n",
    "\n",
    "Saving the Logistic Regression Model:\n",
    "\n",
    "What: The logistic_regression_model.pkl file stores the trained Logistic Regression model.\n",
    "Why: Saves time and resources by preventing the need to retrain the model each time you want to use it. You can directly load the model for making predictions on new data.\n",
    "\n",
    "Saving the Decision Tree Model:\n",
    "\n",
    "What: The decision_tree_model.pkl file stores the trained Decision Tree model.\n",
    "Why: Similar to the Logistic Regression model, it allows for reuse and avoids retraining, making future predictions faster and more efficient.\n",
    "\n",
    "Why Save the Models?\n",
    "Efficiency: Training models can be time-consuming and resource-intensive. Saving them prevents the need for retraining, which is especially important when using large datasets.\n",
    "Reusability: Saved models can be reused in different environments (e.g., production systems, applications), facilitating deployment and integration.\n",
    "Model Deployment: Models need to be deployed in real-time systems for making predictions on live data. Saving models ensures they are ready for deployment without retraining.\n",
    "\n",
    "Benefits\n",
    "Time-Saving: You can quickly load saved models and make predictions without going through the expensive training process.\n",
    "Consistency: Saved models provide consistent predictions across different environments or times.\n",
    "Easy Integration: The models can be integrated into applications (e.g., web or mobile) to provide real-time predictions.\n",
    "\n",
    "In Summary:\n",
    "Saving the scaler and models allows for efficient, consistent, and reusable predictions without retraining, which is crucial for deploying machine learning systems in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "# Save the Logistic Regression model\n",
    "with open('logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(log_reg, file)\n",
    "\n",
    "# Save the Decision Tree model\n",
    "with open('decision_tree_model.pkl', 'wb') as file:\n",
    "    pickle.dump(decision_tree, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Discussion \n",
    "The Logistic regression model outperforms the Decision Tree model in terms of accuracy. \n",
    "With a significantly higher accuracy rate (84.87% compared to 73.68%), Logistic \n",
    "Regression is a more reliable model for predicting loan approval in this particular case. \n",
    "Therefore, it would be more appropriate to use logistic regression for making future \n",
    "predictions of Loan Approval. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
